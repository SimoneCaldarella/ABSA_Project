{"cells":[{"cell_type":"markdown","metadata":{"id":"BJc6DzdrIcs5"},"source":["# **NLU Final Project: *Target/Aspect Based Sentiment Analysis (T/ABSA)***\n","\n","### Author info: \n","\n","    Student name: Simone Caldarella\n","    Student Number: 224434\n","    Email: simone.caldarella@studenti.unitn.it\n","\n","### Other info:\n","\n","    Dataset: https://github.com/lixin4ever/E2E-TBSA\n","    Paper: https://aclanthology.org/P19-1051.pdf"]},{"cell_type":"markdown","metadata":{"id":"pfAhSskfeLxU"},"source":["# **CODE**"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"uz7Rm4IJfxc1","executionInfo":{"status":"ok","timestamp":1641327067618,"user_tz":-60,"elapsed":1296,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"}}},"outputs":[],"source":["try:\n","    import torch\n","    from torch.utils.data import Dataset\n","    from torch.utils.data import DataLoader\n","    import numpy as np\n","    import matplotlib.pyplot as plt\n","    import time\n","    import os\n","    import pprint\n","    import matplotlib.pyplot as plt\n","    import tqdm\n","    from datetime import datetime\n","except:\n","    print(\"Plase install all the modules required\")\n","    exit()\n","\n","# Code for mounting drive if force remount failed\n","\n","__COLAB__ = True # Use True if you are using this in colab\n","\n","__BASEPATH__ = '/content/drive/MyDrive/NLU_Project'\n","__DATA__ = 'Data'\n","\n","if __COLAB__:\n","    from google.colab import drive\n","    if os.path.isdir('/content/drive') is False:\n","        drive.mount('/content/drive', force_remount=False)\n","\n","try:\n","    import transformers\n","except:\n","    if __COLAB__:\n","        !pip install transformers\n","\n","    else:\n","        print(\"Please install transformers library before starting\")\n","        exit()\n","        \n","from transformers import DistilBertModel, BertTokenizer, BertForQuestionAnswering, DistilBertTokenizer, DistilBertForQuestionAnswering, DistilBertConfig, BertConfig, BertModel\n","from transformers.optimization import get_linear_schedule_with_warmup"]},{"cell_type":"markdown","metadata":{"id":"jepgL8p_eNmm"},"source":["## PRE-PROCESSING and TEMPLATES"]},{"cell_type":"markdown","metadata":{"id":"yvVH1NVod0_p"},"source":["### Library Used for reproducibility of multi-target extraction"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1641324814630,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"l73C4vUse02V"},"outputs":[],"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import copy\n","import json\n","import math\n","import six\n","import torch\n","import torch.nn as nn\n","from torch.nn import CrossEntropyLoss"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":672,"status":"ok","timestamp":1641324815282,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"zpWq2ZLEeShL"},"outputs":[],"source":["def gelu(x):\n","    \"\"\"Implementation of the gelu activation function.\n","        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n","        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n","    \"\"\"\n","    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n","    \n","class BERTLayerNorm(torch.nn.Module):\n","    def __init__(self, config, variance_epsilon=1e-12):\n","        \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n","        \"\"\"\n","        super(BERTLayerNorm, self).__init__()\n","        self.gamma = torch.nn.Parameter(torch.ones(config.hidden_size))\n","        self.beta = torch.nn.Parameter(torch.zeros(config.hidden_size))\n","        self.variance_epsilon = variance_epsilon\n","\n","    def forward(self, x):\n","        u = x.mean(-1, keepdim=True)\n","        s = (x - u).pow(2).mean(-1, keepdim=True)\n","        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n","        return self.gamma * x + self.beta\n","\n","\n","class BERTEmbeddings(torch.nn.Module):\n","    def __init__(self, config):\n","        super(BERTEmbeddings, self).__init__()\n","        \"\"\"Construct the embedding module from word, position and token_type embeddings.\n","        \"\"\"\n","        self.word_embeddings = torch.nn.Embedding(config.vocab_size, config.hidden_size)\n","        self.position_embeddings = torch.nn.Embedding(config.max_position_embeddings, config.hidden_size)\n","        self.token_type_embeddings = torch.nn.Embedding(config.type_vocab_size, config.hidden_size)\n","\n","        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n","        # any TensorFlow checkpoint file\n","        self.LayerNorm = BERTLayerNorm(config)\n","        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n","\n","    def forward(self, input_ids, token_type_ids=None):\n","        seq_length = input_ids.size(1)\n","        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)\n","        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n","        if token_type_ids is None:\n","            token_type_ids = torch.zeros_like(input_ids)\n","\n","        words_embeddings = self.word_embeddings(input_ids)\n","        position_embeddings = self.position_embeddings(position_ids)\n","        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n","\n","        embeddings = words_embeddings + position_embeddings + token_type_embeddings\n","        embeddings = self.LayerNorm(embeddings)\n","        embeddings = self.dropout(embeddings)\n","        return embeddings\n","\n","\n","class BERTSelfAttention(torch.nn.Module):\n","    def __init__(self, config):\n","        super(BERTSelfAttention, self).__init__()\n","        if config.hidden_size % config.num_attention_heads != 0:\n","            raise ValueError(\n","                \"The hidden size (%d) is not a multiple of the number of attention \"\n","                \"heads (%d)\" % (config.hidden_size, config.num_attention_heads))\n","        self.num_attention_heads = config.num_attention_heads\n","        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n","        self.all_head_size = self.num_attention_heads * self.attention_head_size\n","\n","        self.query = torch.nn.Linear(config.hidden_size, self.all_head_size)\n","        self.key = torch.nn.Linear(config.hidden_size, self.all_head_size)\n","        self.value = torch.nn.Linear(config.hidden_size, self.all_head_size)\n","\n","        self.dropout = torch.nn.Dropout(config.attention_probs_dropout_prob)\n","\n","    def transpose_for_scores(self, x):\n","        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n","        x = x.view(*new_x_shape)\n","        return x.permute(0, 2, 1, 3)\n","\n","    def forward(self, hidden_states, attention_mask):\n","        mixed_query_layer = self.query(hidden_states)   # [N, L, H]\n","        mixed_key_layer = self.key(hidden_states)\n","        mixed_value_layer = self.value(hidden_states)\n","\n","        query_layer = self.transpose_for_scores(mixed_query_layer)  # [N, K, L, H//K]\n","        key_layer = self.transpose_for_scores(mixed_key_layer)\n","        value_layer = self.transpose_for_scores(mixed_value_layer)\n","\n","        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n","        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))   # [N, K, L, L]\n","        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n","        # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n","        attention_scores = attention_scores + attention_mask\n","\n","        # Normalize the attention scores to probabilities.\n","        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n","\n","        # This is actually dropping out entire tokens to attend to, which might\n","        # seem a bit unusual, but is taken from the original Transformer paper.\n","        attention_probs = self.dropout(attention_probs)\n","\n","        context_layer = torch.matmul(attention_probs, value_layer)  # [N, K, L, H//K]\n","        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()  # [N, L, K, H//K]\n","        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n","        context_layer = context_layer.view(*new_context_layer_shape)    # [N, L, H]\n","        return context_layer\n","\n","\n","class BERTSelfOutput(torch.nn.Module):\n","    def __init__(self, config):\n","        super(BERTSelfOutput, self).__init__()\n","        self.dense = torch.nn.Linear(config.hidden_size, config.hidden_size)\n","        self.LayerNorm = BERTLayerNorm(config)\n","        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n","\n","    def forward(self, hidden_states, input_tensor):\n","        hidden_states = self.dense(hidden_states)\n","        hidden_states = self.dropout(hidden_states)\n","        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n","        return hidden_states\n","\n","\n","class BERTAttention(torch.nn.Module):\n","    def __init__(self, config):\n","        super(BERTAttention, self).__init__()\n","        self.self = BERTSelfAttention(config)\n","        self.output = BERTSelfOutput(config)\n","\n","    def forward(self, input_tensor, attention_mask):\n","        self_output = self.self(input_tensor, attention_mask)\n","        attention_output = self.output(self_output, input_tensor)\n","        return attention_output\n","\n","\n","class BERTIntermediate(torch.nn.Module):\n","    def __init__(self, config):\n","        super(BERTIntermediate, self).__init__()\n","        self.dense = torch.nn.Linear(config.hidden_size, config.intermediate_size)\n","        self.intermediate_act_fn = gelu\n","\n","    def forward(self, hidden_states):\n","        hidden_states = self.dense(hidden_states)\n","        hidden_states = self.intermediate_act_fn(hidden_states)\n","        return hidden_states\n","\n","\n","class BERTOutput(torch.nn.Module):\n","    def __init__(self, config):\n","        super(BERTOutput, self).__init__()\n","        self.dense = torch.nn.Linear(config.intermediate_size, config.hidden_size)\n","        self.LayerNorm = BERTLayerNorm(config)\n","        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n","\n","    def forward(self, hidden_states, input_tensor):\n","        hidden_states = self.dense(hidden_states)\n","        hidden_states = self.dropout(hidden_states)\n","        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n","        return hidden_states"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1641324815283,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"Mw4aV6kRd05n"},"outputs":[],"source":["class BERTLayer(torch.nn.Module):\n","    def __init__(self, config):\n","        super(BERTLayer, self).__init__()\n","        self.attention = BERTAttention(config)\n","        self.intermediate = BERTIntermediate(config)\n","        self.output = BERTOutput(config)\n","\n","    def forward(self, hidden_states, attention_mask):\n","        attention_output = self.attention(hidden_states, attention_mask)\n","        intermediate_output = self.intermediate(attention_output)\n","        layer_output = self.output(intermediate_output, attention_output)\n","        return layer_output\n","\n","\n","class BERTEncoder(torch.nn.Module):\n","    def __init__(self, config):\n","        super(BERTEncoder, self).__init__()\n","        layer = BERTLayer(config)\n","        self.layer = torch.nn.ModuleList([copy.deepcopy(layer) for _ in range(config.num_hidden_layers)])    \n","\n","    def forward(self, hidden_states, attention_mask):\n","        all_encoder_layers = []\n","        for layer_module in self.layer:\n","            hidden_states = layer_module(hidden_states, attention_mask)\n","            all_encoder_layers.append(hidden_states)\n","        return all_encoder_layers\n","\n","\n","class BERTPooler(torch.nn.Module):\n","    def __init__(self, config):\n","        super(BERTPooler, self).__init__()\n","        self.dense = torch.nn.Linear(config.hidden_size, config.hidden_size)\n","        self.activation = torch.nn.Tanh()\n","\n","    def forward(self, hidden_states):\n","        # We \"pool\" the model by simply taking the hidden state corresponding\n","        # to the first token.\n","        first_token_tensor = hidden_states[:, 0]\n","        pooled_output = self.dense(first_token_tensor)\n","        pooled_output = self.activation(pooled_output)\n","        return pooled_output"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1641324815283,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"y1g1VO1EZuFy"},"outputs":[],"source":["class BertModelOlder(torch.nn.Module):\n","    \"\"\"BERT model (\"Bidirectional Embedding Representations from a Transformer\").\n","    Example usage:\n","    ```python\n","    # Already been converted into WordPiece token ids\n","    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n","    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n","    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 2, 0]])\n","    config = modeling.BertConfig(vocab_size=32000, hidden_size=512,\n","        num_hidden_layers=8, num_attention_heads=6, intermediate_size=1024)\n","    model = modeling.BertModel(config=config)\n","    all_encoder_layers, pooled_output = model(input_ids, token_type_ids, input_mask)\n","    ```\n","    \"\"\"\n","    def __init__(self, config: BertConfig):\n","        \"\"\"Constructor for BertModel.\n","        Args:\n","            config: `BertConfig` instance.\n","        \"\"\"\n","        super(BertModelOlder, self).__init__()\n","        self.embeddings = BERTEmbeddings(config)\n","        self.encoder = BERTEncoder(config)\n","        self.pooler = BERTPooler(config)\n","\n","    def forward(self, input_ids, token_type_ids=None, attention_mask=None):\n","        if attention_mask is None:\n","            attention_mask = torch.ones_like(input_ids)\n","        if token_type_ids is None:\n","            token_type_ids = torch.zeros_like(input_ids)\n","\n","        # We create a 3D attention mask from a 2D tensor mask.\n","        # Sizes are [batch_size, 1, 1, to_seq_length]\n","        # So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\n","        # this attention mask is more simple than the triangular masking of causal attention\n","        # used in OpenAI GPT, we just need to prepare the broadcast dimension here.\n","        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n","\n","        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n","        # masked positions, this operation will create a tensor which is 0.0 for\n","        # positions we want to attend and -10000.0 for masked positions.\n","        # Since we are adding it to the raw scores before the softmax, this is\n","        # effectively the same as removing these entirely.\n","        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype) # fp16 compatibility\n","        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n","\n","        embedding_output = self.embeddings(input_ids, token_type_ids)\n","        all_encoder_layers = self.encoder(embedding_output, extended_attention_mask)\n","        sequence_output = all_encoder_layers[-1]\n","        pooled_output = self.pooler(sequence_output)\n","        return all_encoder_layers, pooled_output\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1641324815284,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"EHIvV7t8WNSn"},"outputs":[],"source":["class BERTLayerNorm(torch.nn.Module):\n","    def __init__(self, config, variance_epsilon=1e-12):\n","        \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n","        \"\"\"\n","        super(BERTLayerNorm, self).__init__()\n","        self.gamma = torch.nn.Parameter(torch.ones(config.hidden_size))\n","        self.beta = torch.nn.Parameter(torch.zeros(config.hidden_size))\n","        self.variance_epsilon = variance_epsilon\n","\n","    def forward(self, x):\n","        u = x.mean(-1, keepdim=True)\n","        s = (x - u).pow(2).mean(-1, keepdim=True)\n","        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n","        return self.gamma * x + self.beta"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1641324815285,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"yjxlkdgQ11n3"},"outputs":[],"source":["class BertForSpanAspectExtraction(torch.nn.Module):\n","    \"\"\"BERT model for Question Answering (span extraction).\n","    This module is composed of the BERT model with a linear layer on top of\n","    the sequence output that computes start_logits and end_logits\n","    Example usage:\n","    ```python\n","    # Already been converted into WordPiece token ids\n","    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n","    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n","    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 2, 0]])\n","    config = BertConfig(vocab_size=32000, hidden_size=512,\n","        num_hidden_layers=8, num_attention_heads=6, intermediate_size=1024)\n","    model = BertForQuestionAnswering(config)\n","    start_logits, end_logits = model(input_ids, token_type_ids, input_mask)\n","    ```\n","    \"\"\"\n","    def __init__(self, config):\n","        super(BertForSpanAspectExtraction, self).__init__()\n","        self.bert = BertModelOlder(config).to(get_device())\n","        self.qa_outputs = torch.nn.Linear(config.hidden_size, 2).to(get_device())\n","        self.loss = TargetExtractionLoss().to(get_device()) \n","        self.M = 20\n","        self.K = 10\n","        self.gamma = 8.5\n","\n","        def init_weights(module):\n","            if isinstance(module, (torch.nn.Linear, torch.nn.Embedding)):\n","                module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n","            elif isinstance(module, BERTLayerNorm):\n","                module.beta.data.normal_(mean=0.0, std=config.initializer_range)\n","                module.gamma.data.normal_(mean=0.0, std=config.initializer_range)\n","            if isinstance(module, torch.nn.Linear):\n","                module.bias.data.zero_()\n","        self.apply(init_weights)\n","\n","    def forward(self, input):\n","        all_encoder_layers, _ = self.bert(**input)\n","        sequence_output = all_encoder_layers[-1]\n","        logits = self.qa_outputs(sequence_output)\n","        start_logits, end_logits = logits.split(1, dim=-1)\n","        start_logits = start_logits.squeeze(-1)\n","        end_logits = end_logits.squeeze(-1)\n","\n","        return start_logits, end_logits\n","\n","    def compute_loss(self, data):\n","        sentence,x,y,polarized_targets = data\n","        yp_s, yp_e = self.forward(x)\n","        loss = self.loss(yp_s, yp_e, y)\n","\n","        return loss\n","\n","    def inference(self, input, debug=False):\n","        '''Non-Max Suppression heuristic algorithm to extract multiple targets'''\n","\n","        # Incomplete forward pass\n","        output = self.forward(input)\n","\n","        g_s = output[0].squeeze(0)\n","        g_e = output[1].squeeze(0)\n","        \n","        # Heuristic multi-span decoding\n","\n","        R = []\n","        U = []\n","        O = []\n","\n","        _, S = torch.topk(g_s, self.M)\n","        _, E = torch.topk(g_e, self.M)\n","\n","\n","        for s in S:\n","            for e in E:\n","                \n","                if s<=e and g_s[s]+g_e[e]>=self.gamma:\n","                    u = g_s[s]+g_e[e] - (e-s+1)\n","                    r = (s,e)\n","                    R.append(r)\n","                    U.append(u)\n","\n","        if debug:\n","            out = zip(R, U)\n","            [print(e) for e in out]\n","\n","        while len(R)>0 and len(O)<self.K:\n","            u = max(U)\n","            l = U.index(u)\n","            r = R[l]\n","            O.append(r)\n","            R.remove(r)\n","            U.remove(u)\n","            i = 0\n","\n","            while i<len(R):\n","                # Overlapping checked as intersection over lists in range of start and end\n","                l_r = list(range(r[0], r[1]+1))\n","                rc = R[i]\n","                l_rc = list(range(rc[0], rc[1]+1))\n","\n","                if (len(set.intersection(set(l_r), set(l_rc)))) > 0:\n","                    R.remove(rc)\n","                    U.remove(U[i])\n","                    i += -1\n","                i += 1\n","\n","        return O   "]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1641324815285,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"CsljTaU415H1"},"outputs":[],"source":["def bert_load_state_dict(model, state_dict):\n","    missing_keys = []\n","    unexpected_keys = []\n","    error_msgs = []\n","\n","    # copy state_dict so _load_from_state_dict can modify it\n","    metadata = getattr(state_dict, '_metadata', None)\n","    state_dict = state_dict.copy()\n","    if metadata is not None:\n","        state_dict._metadata = metadata\n","\n","    def load(module, prefix=''):\n","        local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\n","        module._load_from_state_dict(\n","            state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n","        for name, child in module._modules.items():\n","            if child is not None:\n","                load(child, prefix + name + '.')\n","\n","    load(model, prefix='' if hasattr(model, 'bert') else 'bert.')\n","\n","    if len(missing_keys) > 0:\n","        print(\"Weights of {} not initialized from pretrained model: {}\".format(\n","            model.__class__.__name__, missing_keys))\n","    if len(unexpected_keys) > 0:\n","        print(\"Weights from pretrained model not used in {}: {}\".format(\n","            model.__class__.__name__, unexpected_keys))\n","    return model"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1641324815286,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"9teVKBJWfetR"},"outputs":[],"source":["# coding=utf-8\n","# Copyright 2018 The Google AI Language Team Authors and The HugginFace Inc. team.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\"PyTorch optimization for BERT model.\"\"\"\n","\n","import math\n","import torch\n","from torch.optim import Optimizer\n","from torch.nn.utils import clip_grad_norm_\n","\n","def warmup_cosine(x, warmup=0.002):\n","    if x < warmup:\n","        return x/warmup\n","    return 0.5 * (1.0 + torch.cos(math.pi * x))\n","\n","def warmup_constant(x, warmup=0.002):\n","    if x < warmup:\n","        return x/warmup\n","    return 1.0\n","\n","def warmup_linear(x, warmup=0.002):\n","    if x < warmup:\n","        return x/warmup\n","    return 1.0 - x\n","\n","SCHEDULES = {\n","    'warmup_cosine':warmup_cosine,\n","    'warmup_constant':warmup_constant,\n","    'warmup_linear':warmup_linear,\n","}\n","\n","\n","class BERTAdam(Optimizer):\n","    \"\"\"Implements BERT version of Adam algorithm with weight decay fix (and no ).\n","    Params:\n","        lr: learning rate\n","        warmup: portion of t_total for the warmup, -1  means no warmup. Default: -1\n","        t_total: total number of training steps for the learning\n","            rate schedule, -1  means constant learning rate. Default: -1\n","        schedule: schedule to use for the warmup (see above). Default: 'warmup_linear'\n","        b1: Adams b1. Default: 0.9\n","        b2: Adams b2. Default: 0.999\n","        e: Adams epsilon. Default: 1e-6\n","        weight_decay_rate: Weight decay. Default: 0.01\n","        max_grad_norm: Maximum norm for the gradients (-1 means no clipping). Default: 1.0\n","    \"\"\"\n","    def __init__(self, params, lr, warmup=-1, t_total=-1, schedule='warmup_linear',\n","                 b1=0.9, b2=0.999, e=1e-6, weight_decay_rate=0.01,\n","                 max_grad_norm=1.0):\n","        if not lr >= 0.0:\n","            raise ValueError(\"Invalid learning rate: {} - should be >= 0.0\".format(lr))\n","        if schedule not in SCHEDULES:\n","            raise ValueError(\"Invalid schedule parameter: {}\".format(schedule))\n","        if not 0.0 <= warmup < 1.0 and not warmup == -1:\n","            raise ValueError(\"Invalid warmup: {} - should be in [0.0, 1.0[ or -1\".format(warmup))\n","        if not 0.0 <= b1 < 1.0:\n","            raise ValueError(\"Invalid b1 parameter: {} - should be in [0.0, 1.0[\".format(b1))\n","        if not 0.0 <= b2 < 1.0:\n","            raise ValueError(\"Invalid b2 parameter: {} - should be in [0.0, 1.0[\".format(b2))\n","        if not e >= 0.0:\n","            raise ValueError(\"Invalid epsilon value: {} - should be >= 0.0\".format(e))\n","        defaults = dict(lr=lr, schedule=schedule, warmup=warmup, t_total=t_total,\n","                        b1=b1, b2=b2, e=e, weight_decay_rate=weight_decay_rate,\n","                        max_grad_norm=max_grad_norm)\n","        super(BERTAdam, self).__init__(params, defaults)\n","\n","    def get_lr(self):\n","        lr = []\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                state = self.state[p]\n","                if len(state) == 0:\n","                    return [0]\n","                if group['t_total'] != -1:\n","                    schedule_fct = SCHEDULES[group['schedule']]\n","                    lr_scheduled = group['lr'] * schedule_fct(state['step']/group['t_total'], group['warmup'])\n","                else:\n","                    lr_scheduled = group['lr']\n","                lr.append(lr_scheduled)\n","        return lr\n","\n","    def step(self, closure=None):\n","        \"\"\"Performs a single optimization step.\n","        Arguments:\n","            closure (callable, optional): A closure that reevaluates the model\n","                and returns the loss.\n","        \"\"\"\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data\n","                if grad.is_sparse:\n","                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n","\n","                state = self.state[p]\n","\n","                # State initialization\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    # Exponential moving average of gradient values\n","                    state['next_m'] = torch.zeros_like(p.data)\n","                    # Exponential moving average of squared gradient values\n","                    state['next_v'] = torch.zeros_like(p.data)\n","\n","                next_m, next_v = state['next_m'], state['next_v']\n","                beta1, beta2 = group['b1'], group['b2']\n","\n","                # Add grad clipping\n","                if group['max_grad_norm'] > 0:\n","                    clip_grad_norm_(p, group['max_grad_norm'])\n","\n","                # Decay the first and second moment running average coefficient\n","                # In-place operations to update the averages at the same time\n","                next_m.mul_(beta1).add_(1 - beta1, grad)\n","                next_v.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n","                update = next_m / (next_v.sqrt() + group['e'])\n","\n","                # Just adding the square of the weights to the loss function is *not*\n","                # the correct way of using L2 regularization/weight decay with Adam,\n","                # since that will interact with the m and v parameters in strange ways.\n","                #\n","                # Instead we want ot decay the weights in a manner that doesn't interact\n","                # with the m/v parameters. This is equivalent to adding the square\n","                # of the weights to the loss with plain (non-momentum) SGD.\n","                if group['weight_decay_rate'] > 0.0:\n","                    update += group['weight_decay_rate'] * p.data\n","\n","                if group['t_total'] != -1:\n","                    schedule_fct = SCHEDULES[group['schedule']]\n","                    lr_scheduled = group['lr'] * schedule_fct(state['step']/group['t_total'], group['warmup'])\n","                else:\n","                    lr_scheduled = group['lr']\n","\n","                update_with_lr = lr_scheduled * update\n","                p.data.add_(-update_with_lr)\n","\n","                state['step'] += 1\n","\n","                # step_size = lr_scheduled * math.sqrt(bias_correction2) / bias_correction1\n","                # bias_correction1 = 1 - beta1 ** state['step']\n","                # bias_correction2 = 1 - beta2 ** state['step']\n","\n","        return loss"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1641324815287,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"Wf87TnzZgdli"},"outputs":[],"source":["def prepare_bertadam(lr, wr, steps, model):\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = ['bias', 'LayerNorm']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n","    optimizer = BERTAdam(optimizer_grouped_parameters,\n","                         lr=lr,\n","                         warmup=wr,\n","                         t_total=steps)\n","    return optimizer"]},{"cell_type":"markdown","metadata":{"id":"36yNWFYVebxL"},"source":["### Utilities"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":543,"status":"ok","timestamp":1641324815816,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"NfjZmW9kSR2v"},"outputs":[],"source":["def get_device():\n","    '''\n","    Dinamically get the current device\n","    '''\n","    \n","    try:\n","        torch.cuda.current_device()\n","        return 'cuda'\n","    except:\n","        return 'cpu'"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1641324815817,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"RRWywM5EempU"},"outputs":[],"source":["def get_BERT(model_class, pretrained_weights, layers, all_params_grad, qa=True, reproducibility=False):\n","    '''\n","    Import pretrained Bert and load it to the device used\n","    '''\n","\n","    if reproducibility:\n","        bert_config = BertConfig.from_json_file(os.path.join(__BASEPATH__, __DATA__, 'bert-base-uncased', 'bert_config.json'))\n","        model = BertForSpanAspectExtraction(bert_config)\n","\n","        model = bert_load_state_dict(model, torch.load(os.path.join(__BASEPATH__, __DATA__, 'bert-base-uncased', 'pytorch_model.bin'), map_location='cpu'))\n","\n","    else:\n","        model = model_class.from_pretrained(pretrained_weights)\n","\n","        if qa==True:\n","            try:\n","                for param in model.qa_outputs.parameters():\n","                    param.requires_grad = True\n","\n","                for l in layers:\n","                    for param in model.distilbert.transformer.layer[l].parameters():\n","                        param.requires_grad = layers[l]\n","            except:\n","                print(\"This is not Bert for Question answering\")\n","        \n","        else:\n","            for l in layers:\n","                    for param in model.transformer.layer[l].parameters():\n","                        param.requires_grad = layers[l]\n","\n","    model = model.to(get_device())\n","\n","    \n","    print(\"###################################################\")\n","    print(\"-------------------Model Choosed-------------------\")\n","    print(model)\n","\n","    return model"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":38,"status":"ok","timestamp":1641324815818,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"louuIp9Te4yM"},"outputs":[],"source":["def my_collate(batch):\n","    '''\n","    Custom collate function for dataloader to handle the variability of targets\n","    '''\n","    encoding = {} # Used as support for the custom collate\n","    texts = [sample[0] for sample in batch]\n","    encoding['input_ids'] = torch.stack([sample[1]['input_ids'].to(get_device()) for sample in batch]).squeeze(1)\n","\n","    # Comment this if you are using distilled bert\n","    #encoding['token_type_ids'] = torch.stack([sample[1]['token_type_ids'].to(get_device()) for sample in batch]).squeeze(1)\n","\n","    encoding['attention_mask'] = torch.stack([sample[1]['attention_mask'].to(get_device()) for sample in batch]).squeeze(1)\n","    targets = [sample[2] for sample in batch]\n","    pol_targets = [sample[3] for sample in batch]\n","    return [texts, encoding, torch.stack(targets).to(get_device()), pol_targets]"]},{"cell_type":"markdown","metadata":{"id":"UP_EVAZUeqKJ"},"source":["### Download and parsing dataset"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1641324815818,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"tHKZtZseev8b"},"outputs":[],"source":["def import_data(tokenizer_class, pretrained_weights, path, max_length):\n","\n","    data = []\n","\n","    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n","\n","    POL = {\n","            'POS':torch.Tensor([1, 0, 0]),\n","            'NEG':torch.Tensor([0, 0, 1]),\n","            'NEU':torch.Tensor([0, 1, 0])\n","        }\n","\n","    # Read file\n","    with open(path) as f:\n","        lines = [line.rstrip() for line in f]\n","\n","    # Parse the file line by line\n","    for line in lines:\n","\n","        polarity_targets = []\n","        s = torch.zeros(max_length)\n","        e = torch.zeros(max_length) \n","\n","        labs = line.split('####')[1].split(' ')\n","        nsentence = line.split('####')[0]\n","        sentence = [t.split('=')[0] for t in labs]\n","        # targets = torch.zeros(max_length)\n","        t_support = [0]*len(sentence)\n","        for i, tag in enumerate(labs):\n","            if tag[-1] != 'O' and tag[-5] == 'T':\n","                t_support[i] = (1, tag[-3:])\n","                # targets[i] = 1\n","    \n","        i = -1\n","\n","        while i < len(t_support):\n","            i += 1\n","\n","            if i == len(t_support):\n","                break\n","\n","            if t_support[i] != 0:\n","                start = i\n","                pol = t_support[i][1]\n","\n","                while i+1 < len(t_support) and t_support[i+1] != 0:\n","                    i += 1\n","\n","                end = i\n","            \n","                tgt = [start, end, POL[pol]]\n","                polarity_targets.append(tgt)\n","\n","                # len+2 used in order to try question answering on context\n","                s[start+1] = 1\n","                e[end+1] = 1 \n","            \n","        targets = torch.stack([s, e])\n","\n","        encoded_sentence = tokenizer.encode_plus(nsentence, return_attention_mask = True, return_tensors = \"pt\", add_special_tokens = True, truncation = True, padding='max_length', max_length=max_length)\n","        data.append([sentence, encoded_sentence, targets, polarity_targets])\n","    \n","    newdata = [el for el in data if el[3] != []]\n","\n","    return newdata"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1641324815821,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"Ipt7kxCte0Je"},"outputs":[],"source":["class SemEval2014(Dataset):\n","    '''\n","    Custom dataset module\n","    '''\n","    def __init__(self, tokenizer_class, pretrained_weights_tokenizer, dataset_path, max_size):\n","        self.samples = import_data(tokenizer_class, pretrained_weights_tokenizer, dataset_path, max_size)\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        sample = self.samples[idx]\n","        # Text, Encoding, Targets, Pol_Targets\n","        return sample[0], sample[1], sample[2], sample[3]"]},{"cell_type":"markdown","metadata":{"id":"FLqFMQz9fDfm"},"source":["### Optimizers"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1641324815822,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"sAz7GEhafEGC"},"outputs":[],"source":["def get_optimizer(parameters, optim, lr, momentum):\n","    '''\n","    Get optimizer dynamically\n","    '''\n","\n","    if optim == 'SGD':\n","        optimizer = torch.optim.SGD(parameters, lr=lr, momentum=momentum)\n","\n","    elif optim == 'Adam':\n","        optimizer = torch.optim.Adam(parameters, lr=lr)\n","\n","    elif optim == 'AdamW':\n","        optimizer = torch.optim.AdamW(parameters, lr=lr)\n","        \n","    return optimizer"]},{"cell_type":"markdown","metadata":{"id":"EeOOtmvDfLN-"},"source":["### Early stopping"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":34,"status":"ok","timestamp":1641324815823,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"gnL4MzcLfMcy"},"outputs":[],"source":["class EarlyStopping:\n","    def __init__(self, min_delta=0, patience=0):\n","        self.min_delta = min_delta\n","        self.patience = patience\n","        self.wait = 0\n","        self.stopped_epoch = 0\n","        self.best = np.Inf\n","        self.stop_training = False\n","    def on_epoch_end(self, epoch, current_value):\n","        if np.greater(self.best, (current_value - self.min_delta)):\n","            self.best = current_value\n","            self.wait = 0\n","        else:\n","            self.wait += 1\n","            if self.wait > self.patience:\n","                self.stopped_epoch = epoch\n","                self.stop_training = True\n","        return self.stop_training"]},{"cell_type":"markdown","metadata":{"id":"ubFpAK24fUM0"},"source":["### Training and Eval templates"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1641324815823,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"CbkRS_rYfaVi"},"outputs":[],"source":["def training(net, optimizer, dataloader, batch_size, sched=None, pc=False):\n","    '''\n","    Training function that correspond to one train pass\n","    '''\n","\n","    pbar = tqdm.tqdm(position=0, leave=True)\n","    pbar.reset(total=int(dataloader.dataset.__len__()/batch_size))\n","    \n","    net.train()\n","    epoch_loss = []\n","    accuracy = []\n","    if pc:\n","        loss = torch.zeros(16)\n","\n","    for i, data in enumerate(dataloader):\n","        # sentence,x,y,polarized_targets <-- data\n","        optimizer.zero_grad()\n","\n","        if pc:\n","            l = net.compute_loss(data)\n","            loss[int(i%16)] = l\n","            if i%16 == 0:\n","                loss = torch.mean(loss)\n","                epoch_loss.append(loss)\n","                loss.backward()\n","                optimizer.step()\n","                loss = torch.zeros(16)\n","                if sched is not None:\n","                    sched.step()\n","\n","        else:\n","            loss = net.compute_loss(data)\n","            if loss != 0:\n","                epoch_loss.append(loss)\n","                loss.backward()\n","                optimizer.step()\n","                if sched is not None:\n","                    sched.step()\n","        pbar.update()\n","    \n","    epoch_loss = torch.tensor(epoch_loss).mean().item()\n","    pbar.close()\n","\n","    return epoch_loss"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1641324815824,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"JJmnCk9yfcyy"},"outputs":[],"source":["def validation(net, dataloader, batch_size):\n","\n","    pbar = tqdm.tqdm(position=0, leave=True)\n","    pbar.reset(total=int(dataloader.dataset.__len__()/batch_size))\n","    \n","    epoch_loss = []\n","    accuracy = []\n","\n","    net.eval()\n","    with torch.no_grad():\n","\n","        for data in dataloader:\n","            loss = net.compute_loss(data)\n","            if loss != 0:\n","                epoch_loss.append(loss)\n","            pbar.update()\n","    \n","    epoch_loss = torch.tensor(epoch_loss).mean().item()\n","    pbar.close()\n","\n","    return epoch_loss"]},{"cell_type":"markdown","metadata":{"id":"7bZSKNlLg6Mt"},"source":["### Train loop"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1641324815825,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"2OJC2YUPfhUp"},"outputs":[],"source":["def train_loop(net, optim, train_dataloader, validation_dataloader, warmup, steps, lr, momentum, epochs, save_path, sched=None, reproducibility=False, pc=False):\n","    '''\n","    Standard training loop with training step and validation step at each epoch\n","    '''\n","    if reproducibility:\n","        optimizer = prepare_bertadam(lr, warmup, steps, net)\n","        sched = None\n","    \n","    else:\n","        optimizer = get_optimizer(net.parameters(), optim, lr, momentum)\n","        if sched == 'linear':\n","            sched = get_linear_schedule_with_warmup(optimizer, int(warmup*steps*epochs), steps, last_epoch=-1)\n","    loss_history_train = {'loss':[]}\n","    loss_history_validation = {'loss':[]}\n","    early_stopping = EarlyStopping(patience=4)\n","    early_stopping.stop_training = False\n","\n","    for epoch in range(epochs):\n","\n","        print('========================== Epoch {} ====================== \\n'.format(epoch))\n","\n","        epoch_loss_train = training(net, optimizer, train_dataloader, train_dataloader.batch_size, sched, pc=pc)\n","        epoch_loss_validation = validation(net, validation_dataloader, validation_dataloader.batch_size)\n","        early_stopping.on_epoch_end(epoch = epoch, current_value = round(epoch_loss_validation,5))\n","        if early_stopping.wait == 0: \n","            bestModel = net\n","            torch.save(bestModel, save_path)\n","            print('New best model saved with loss:', epoch_loss_validation)\n","\n","        loss_history_train['loss'].append(epoch_loss_train)\n","        loss_history_validation['loss'].append(epoch_loss_validation)\n","\n","        print('\\n Results:')\n","        print('     - Training loss:', epoch_loss_train)\n","        print('     - Validation loss:', epoch_loss_validation)\n","        print('\\n')\n","\n","    final_path = save_path[:-4]+\"_final.pth\"\n","    torch.save(net, final_path)\n","\n","    return loss_history_train, loss_history_validation"]},{"cell_type":"markdown","metadata":{"id":"qLwQF09mfjN-"},"source":["## TARGET EXTRACTION"]},{"cell_type":"markdown","metadata":{"id":"1l47JCkcflAy"},"source":["### Custom Loss function for target extraction"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":660,"status":"ok","timestamp":1641324900422,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"y-5cMruifoz2"},"outputs":[],"source":["class TargetExtractionLoss(torch.nn.Module):\n","    '''\n","    Reproduction of the loss in the paper, with some possible modifications\n","    '''\n","    \n","    def __init__(self):\n","        super(TargetExtractionLoss,self).__init__()\n","        \n","    \n","    def forward(self, yp_s, yp_e, y):\n","        \n","        y_s = y[:,0,:] # starts label\n","        y_e = y[:,1,:] # ends label\n","\n","        log_softmax = torch.nn.LogSoftmax(dim=-1)\n","        log_probs_s = log_softmax(yp_s)\n","        log_probs_e = log_softmax(yp_e)\n","        \n","        if torch.sum(y_s.to(dtype=log_probs_s.dtype)) == 0:\n","            loss = 0\n","\n","        else:\n","            loss_s = -1 * torch.mean(torch.sum(y_s.to(dtype=log_probs_s.dtype) * log_probs_s, dim=-1) / torch.sum(y_s.to(dtype=log_probs_s.dtype), dim=-1))\n","            loss_e = -1 * torch.mean(torch.sum(y_e.to(dtype=log_probs_e.dtype) * log_probs_e, dim=-1) / torch.sum(y_e.to(dtype=log_probs_e.dtype), dim=-1))\n","            \n","            loss = (loss_s+loss_e)/2\n","            print(loss)\n","        \n","        return loss"]},{"cell_type":"markdown","metadata":{"id":"BoXnvkVof2ey"},"source":["### Target extraction model"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1641324900899,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"kPMqV20sfvqZ"},"outputs":[],"source":["class TargetExtractionNet(torch.nn.Module):\n","    '''\n","    Model based on the paper, composed by a backbone and 2 linear layers, one for the\n","    distribution of the starts and the other for the distribution of the ends\n","    '''\n","\n","    def __init__(self, backbone, gamma, K=10, M=20, qa=False):\n","        super(TargetExtractionNet, self).__init__()\n","        self.gamma = gamma\n","        self.K = K\n","        self.M = M\n","        self.qa = qa\n","        self.backbone = backbone\n","        \n","        # First order parameters\n","\n","        if not self.qa:\n","            # self.w_s = torch.nn.Parameter(torch.rand(768), requires_grad=True).to(get_device())\n","            # self.w_e = torch.nn.Parameter(torch.rand(768), requires_grad=True).to(get_device())\n","            self.w_s = torch.nn.Linear(768, 1, bias=True, device=get_device())\n","            self.w_e = torch.nn.Linear(768, 1, bias=True, device=get_device())\n","        \n","        # Activation\n","        #self.softmax = torch.nn.Softmax(dim=-1).to(get_device())\n","\n","        # Loss function\n","        self.loss = TargetExtractionLoss().to(get_device())\n","\n","    def forward(self, input):\n","\n","        # Backbone pass\n","        output = self.backbone(**input)\n","\n","        if not self.qa:\n","            output = output[0] # size = (batch_size, sentence_max_size, bert_hidden_size=768)\n","\n","            # Start distribution\n","            # output_s = torch.matmul(output, self.w_s)\n","            output_s = self.w_s(output).squeeze()\n","\n","            # End distribution\n","            # output_e = torch.matmul(output, self.w_e)\n","            output_e = self.w_e(output).squeeze()\n","        \n","        else:\n","\n","            output_s = output.start_logits\n","            output_e = output.end_logits\n","    \n","        output = [output_s, output_e] # Aggregate output\n","\n","        return output\n","\n","    def compute_loss(self, data):\n","        sentence,x,y,polarized_targets = data\n","        yp_s, yp_e = self.forward(x)\n","        loss = self.loss(yp_s, yp_e, y)\n","\n","        return loss\n","\n","    def inference(self, input, debug=False):\n","        '''Non-Max Suppression heuristic algorithm to extract multiple targets'''\n","\n","        # Incomplete forward pass\n","        output = self.backbone(**input)\n","\n","        if not self.qa:\n","            output = output[0]\n","            # g_s = torch.matmul(output, self.w_s)[0,:]\n","            # g_e = torch.matmul(output, self.w_e)[0,:]\n","\n","            g_s = self.w_s(output).squeeze()\n","            g_e = self.w_e(output).squeeze()\n","\n","        else:\n","\n","            g_s = output.start_logits.squeeze(0)\n","            g_e = output.end_logits.squeeze(0)\n","        \n","        # Heuristic multi-span decoding\n","\n","        R = []\n","        U = []\n","        O = []\n","\n","        _, S = torch.topk(g_s, self.M)\n","        _, E = torch.topk(g_e, self.M)\n","\n","\n","        for s in S:\n","            for e in E:\n","                \n","                if s<=e and g_s[s]+g_e[e]>=self.gamma:\n","                    u = g_s[s]+g_e[e] - (e-s+1)\n","                    r = (s,e)\n","                    R.append(r)\n","                    U.append(u)\n","\n","        if debug:\n","            out = zip(R, U)\n","            [print(e) for e in out]\n","\n","        while len(R)>0 and len(O)<self.K:\n","            u = max(U)\n","            l = U.index(u)\n","            r = R[l]\n","            O.append(r)\n","            R.remove(r)\n","            U.remove(u)\n","            i = 0\n","\n","            while i<len(R):\n","                # Overlapping checked as intersection over lists in range of start and end\n","                l_r = list(range(r[0], r[1]+1))\n","                rc = R[i]\n","                l_rc = list(range(rc[0], rc[1]+1))\n","\n","                if (len(set.intersection(set(l_r), set(l_rc)))) > 0:\n","                    R.remove(rc)\n","                    U.remove(U[i])\n","                    i += -1\n","                i += 1\n","\n","        return O"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1641324900900,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"rJs9cwyIf6_R"},"outputs":[],"source":["def init_target_extraction_model(model, reproducibility=False):\n","    \n","    backbone = get_BERT(model['model_class'], model['pretrained_weights_model'], model['layers'], model['all_params_grad'], model['qa'], reproducibility)\n","    \n","    if not reproducibility:\n","        net = TargetExtractionNet(backbone, model['gamma'], model['K'], model['M'], model['qa'])\n","    else:\n","        net = backbone\n","\n","    return net"]},{"cell_type":"markdown","metadata":{"id":"T8VVkWtlf-Je"},"source":["### Target extractor main loop"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1641324900900,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"xK2W_JgVf68P"},"outputs":[],"source":["def te_main_loop(training):   \n","    training_dataset = SemEval2014(training['data']['tokenizer_class'], training['data']['pretrained_weights_tokenizer'], training['path']['train_path'], training['data']['max_length'])\n","    train_size = int(training_dataset.__len__()*training['data']['train_split'])\n","    validation_size = training_dataset.__len__() - train_size\n","    train_set, validation_set = torch.utils.data.random_split(training_dataset, [train_size, validation_size])\n","    steps = training['epochs']*int(training_dataset.__len__()/training['batch_size'])\n","\n","    train_dataloader = DataLoader(train_set, batch_size=training['batch_size'], collate_fn=my_collate, shuffle=True)\n","    validation_dataloader = DataLoader(validation_set, batch_size=training['batch_size'], collate_fn=my_collate, shuffle=False)\n","\n","    te_net = init_target_extraction_model(training['model'], training['reproducibility'])\n","\n","    train_loss, valid_loss = train_loop(te_net, training['optimizer']['name'], train_dataloader, \n","                                        validation_dataloader, training['optimizer']['warmup'], steps, \n","                                        training['optimizer']['lr'], training['optimizer']['momentum'], \n","                                        training['epochs'], training['path']['te_net_save_path'], \n","                                        training['optimizer']['scheduler'], training['reproducibility']\n","                                        )   \n","    \n","    return train_loss, valid_loss, te_net"]},{"cell_type":"markdown","metadata":{"id":"WUE08zJ8gHH3"},"source":["### Target extraction only evaluation"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1641324900900,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"3-pJSdaOgPC7"},"outputs":[],"source":["def target_extraction_eval(evaluation):\n","    test_set = SemEval2014(evaluation['data']['tokenizer_class'], evaluation['data']['pretrained_weights_tokenizer'], \n","                           evaluation['path']['test_path'], evaluation['data']['max_length'])\n","    test_dataloader = DataLoader(test_set, batch_size=1, collate_fn=my_collate, shuffle=False)\n","\n","    f1s = {}\n","\n","    step = 1 # fixed\n","    gamma_range = evaluation['gamma_range']\n","    gamma_space=np.arange(0,gamma_range[1])*step+gamma_range[0]\n","\n","    for gamma in gamma_space:\n","        f1s[gamma] = []\n","\n","    pbar = tqdm.tqdm(position=0, leave=True)\n","\n","    for te_net_path in os.listdir(evaluation['path']['base_path_te_eval']):\n","        if te_net_path[-3:] == 'pth':\n","            net = torch.load(os.path.join(evaluation['path']['base_path_te_eval'],te_net_path), map_location='cpu').to(get_device())\n","\n","            net.eval()\n","            print(\"---------------------\")\n","            print(\"\\n Eval started\")\n","\n","            for gamma in gamma_space:\n","\n","                net.gamma = gamma\n","                conf_matrix = torch.zeros(2, 2)\n","            \n","                with torch.no_grad():\n","                    print('\\n ---------------------')\n","                    print('\\n Gamma: {} \\n'.format(gamma))\n","\n","                    pbar.reset(total=int(len(test_dataloader)))\n","\n","                    for i, element in enumerate(test_dataloader):\n","                        o = net.inference(element[1], False)\n","                        pr = [tuple([int(el[0])-1,int(el[1])-1]) for el in o]\n","                        gt_raw = element[3][0]\n","                        gt = []\n","                        for c in gt_raw:\n","                            gt.append((c[0],c[1]))\n","\n","                        \n","                        for p in pr:\n","                            if p in gt: \n","                                # True Positive\n","                                conf_matrix[0,0] += 1\n","                            else:\n","                                # False Positive\n","                                conf_matrix[1,0] += 1\n","                        \n","                        for g in gt:\n","                            if g not in pr:\n","                                conf_matrix[0,1] += 1\n","                        \n","                        pbar.update()\n","                        \n","                    \n","                    p = conf_matrix[0,0]/(conf_matrix[0,0] + conf_matrix[1,0])\n","                    r = conf_matrix[0,0]/(conf_matrix[0,1] + conf_matrix[0,0])\n","                    f1 = (2 * p * r) / (p + r)\n","\n","                    retrieved = conf_matrix[0,0] + conf_matrix[1,0]\n","                    common = conf_matrix[0,0]\n","\n","                f1s[gamma].append(f1)\n","\n","                print(\"\\n \\n Precision: {}, Recall: {}, F1: {}, Retrieved: {}, Common: {}\".format(p, r, f1, retrieved, common))\n","        \n","    pbar.close()\n","    return f1s"]},{"cell_type":"markdown","metadata":{"id":"G_O53G5jgVMe"},"source":["## POLARITY CLASSIFICATION"]},{"cell_type":"markdown","metadata":{"id":"xYH-4lB9JdVy"},"source":["### Custom loss for polarity classification"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"1SdwMVwa4UNy","executionInfo":{"status":"ok","timestamp":1641324900901,"user_tz":-60,"elapsed":10,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"}}},"outputs":[],"source":["class PolarityClassificationLoss(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(PolarityClassificationLoss, self).__init__()\n","        \n","    def forward(self, p, pol):\n","        cross = - torch.sum(pol.to(get_device())*torch.log(p))\n","        return cross"]},{"cell_type":"markdown","metadata":{"id":"7_OLXvx5Jjou"},"source":["### Polarity classification model"]},{"cell_type":"code","execution_count":103,"metadata":{"id":"3uaHz2uBgY-f","executionInfo":{"status":"ok","timestamp":1641328868137,"user_tz":-60,"elapsed":827,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"}}},"outputs":[],"source":["class PolarityClassificationNet(torch.nn.Module):\n","\n","    def __init__(self, backbone):\n","        super(PolarityClassificationNet, self).__init__()\n","        self.backbone = backbone.to(get_device())\n","        \n","        # First order parameters\n","        self.w_a = torch.nn.Parameter(torch.rand(768), requires_grad=True).to(get_device())\n","        self.W_v = torch.nn.Parameter(torch.rand(768, 768), requires_grad=True).to(get_device())\n","        self.W_p = torch.nn.Parameter(torch.rand(3, 768), requires_grad=True).to(get_device())\n","        \n","        # Activation\n","        self.softmax = torch.nn.Softmax(dim=-1).to(get_device())\n","\n","        # Loss function\n","        self.loss = PolarityClassificationLoss().to(get_device())\n","        \n","\n","    def forward(self, x, span):\n","\n","        # Forward should be done for each target in a sentence\n","        \n","        h = self.backbone(**x)[0]\n","        # One Target, batch doesn't taken in account\n","        h_t = h[0, span[0]+1:span[1]+2]  # +1 and +2 added due to the special tokens and due to the last element included\n","        alpha = torch.matmul(h_t.to(get_device()), self.w_a.to(get_device()))\n","        alpha = self.softmax(alpha)\n","\n","        # Transpose needed for coefficients multiplication\n","        v = torch.sum(h_t.transpose(0, 1)*alpha, dim=1) \n","        \n","        temp =  torch.tanh(torch.matmul(self.W_v.to(get_device()), v))\n","        g = torch.matmul(self.W_p.to(get_device()), temp) # Likelihood for each sentiment class\n","        p = self.softmax(g)\n","\n","        return p  \n","\n","    def compute_loss(self, data):\n","\n","        sentence,x,y,polarity_targets = data\n","        loss = []\n","        if polarity_targets[0] != []:\n","            for i, pol in enumerate(polarity_targets[0]):\n","                p = self.forward(x, pol)\n","                loss_target = self.loss(p, pol[2])\n","                loss.append(loss_target)\n","            \n","            loss = sum(loss)/(i+1)\n","        \n","        else:\n","            loss = 0\n","\n","        return loss\n"]},{"cell_type":"code","execution_count":104,"metadata":{"id":"SlfyE8XvgawP","executionInfo":{"status":"ok","timestamp":1641328869890,"user_tz":-60,"elapsed":10,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"}}},"outputs":[],"source":["def init_polarity_classification_model(model):\n","    \n","    backbone = get_BERT(model['model_class'], model['pretrained_weights_model'], model['layers'], model['all_params_grad'], model['qa'])\n","    net = PolarityClassificationNet(backbone)\n","\n","    return net"]},{"cell_type":"markdown","metadata":{"id":"zVcBAkL5HEJH"},"source":["### Polarity Classification main loop"]},{"cell_type":"code","execution_count":105,"metadata":{"id":"nGIpvOwqHJeN","executionInfo":{"status":"ok","timestamp":1641328870485,"user_tz":-60,"elapsed":6,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"}}},"outputs":[],"source":["def pc_main_loop(training):   \n","    training_dataset = SemEval2014(training['data']['tokenizer_class'], training['data']['pretrained_weights_tokenizer'], training['path']['train_path'], training['data']['max_length'])\n","    train_size = int(training_dataset.__len__()*training['data']['train_split'])\n","    validation_size = training_dataset.__len__() - train_size\n","    train_set, validation_set = torch.utils.data.random_split(training_dataset, [train_size, validation_size])\n","    steps = training['epochs']*int(training_dataset.__len__()/training['batch_size'])\n","\n","    train_dataloader = DataLoader(train_set, batch_size=training['batch_size'], collate_fn=my_collate, shuffle=True)\n","    validation_dataloader = DataLoader(validation_set, batch_size=training['batch_size'], collate_fn=my_collate, shuffle=False)\n","\n","    el = next(iter(train_dataloader))\n","    pc_net = init_polarity_classification_model(training['model'])\n","\n","    train_loss, valid_loss = train_loop(pc_net, training['optimizer']['name'], train_dataloader, \n","                                        validation_dataloader, training['optimizer']['warmup'], steps, \n","                                        training['optimizer']['lr'], training['optimizer']['momentum'], \n","                                        training['epochs'], training['path']['pc_net_save_path'], \n","                                        sched=training['optimizer']['scheduler'], pc=True)\n","    \n","    return train_loss, valid_loss, pc_net"]},{"cell_type":"markdown","metadata":{"id":"JCaQ0Mv4Jtqm"},"source":["### Polarity classification only evaluation"]},{"cell_type":"code","execution_count":106,"metadata":{"id":"8nbCfAhZJy2p","executionInfo":{"status":"ok","timestamp":1641328871612,"user_tz":-60,"elapsed":9,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"}}},"outputs":[],"source":["def polarity_classification_eval(evaluation):\n","    test_set = SemEval2014(evaluation['data']['tokenizer_class'], evaluation['data']['pretrained_weights_tokenizer'], \n","                           evaluation['path']['test_path'], evaluation['data']['max_length'])\n","    test_dataloader = DataLoader(test_set, batch_size=1, collate_fn=my_collate, shuffle=False)\n","\n","    pbar = tqdm.tqdm(position=0, leave=True)\n","\n","    for pc_net_path in os.listdir(evaluation['path']['base_path_pc_eval']):\n","        if pc_net_path[-3:] == 'pth':\n","            net = torch.load(os.join.path(evaluation['path']['base_path_pc_eval'],pc_net_path)).to(get_device())\n","\n","            net.eval()\n","            print(\"---------------------\")\n","            print(\"\\n Eval started\")\n","\n","            \n","            conf_matrix = torch.zeros(3, 3)\n","\n","                \n","            #     pos neu neg --> Predicted\n","            #     ___ ___ ___\n","            # pos|___|___|___|\n","            # neu|___|___|___|\n","            # neg|___|___|___|\n","\n","            \n","            with torch.no_grad():\n","\n","                pbar.reset(total=int(len(test_dataloader)))\n","                correct = 0\n","                total = 0\n","\n","                for data in test_dataloader:\n","                    sentence,x,y,polarity_targets = data\n","                    if polarity_targets[0] != []:\n","                        for pol in polarity_targets[0]:\n","                            p = net.forward(x, pol)\n","                            pred = torch.argmax(p)\n","                            corr = torch.argmax(pol[2])\n","\n","                            if pred == corr:\n","                                correct+=1\n","                                total+=1\n","                            else:\n","                                total+=1\n","\n","                    pbar.update()\n","                        \n","            print(\"Accuracy:\", correct/total)\n","\n","    pbar.close()"]},{"cell_type":"markdown","metadata":{"id":"u9pXMhHEgcT-"},"source":["## WORKSPACES"]},{"cell_type":"markdown","metadata":{"id":"onehYClh_esk"},"source":["### Target extraction train"]},{"cell_type":"code","execution_count":107,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1641328872880,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"1dNOu9d-52Mo"},"outputs":[],"source":["def te_train(restart):\n","    path = {}\n","    path['train_path'] = os.path.join(__BASEPATH__, __DATA__, 'Dataset_semeval_2014', 'laptop14_train.txt')\n","    path['test_path'] = os.path.join(__BASEPATH__, __DATA__, 'Dataset_semeval_2014','laptop14_test.txt')\n","\n","    dir = os.path.join(__BASEPATH__, __DATA__, 'Previous_trainings', datetime.now().strftime('%Y_%m_%d_%H:%M:%S'))\n","    os.mkdir(dir)\n","\n","    for res in range(restart):\n","        path['te_net_save_path'] = os.path.join(dir,'target_extraction_'+str(res)+'.pth')\n","\n","        optim = {}\n","        optim['name'] = 'AdamW'\n","        optim['lr'] = 3e-4\n","        optim['momentum'] = 0.9\n","        optim['scheduler'] = 'linear'\n","        optim['warmup'] = 0.1\n","\n","        model = {}\n","        model['gamma'] = 9\n","        model['K'] = 10\n","        model['M'] = 20\n","        model['model_class'] = BertModel\n","        model['pretrained_weights_model'] = 'bert-base-uncased'\n","        model['layers'] = {} # Manually set grad True or False --> Example: {1:True, 2:False}\n","        model['all_params_grad'] = True\n","\n","        if model['model_class'] == DistilBertForQuestionAnswering or model['model_class'] == BertForQuestionAnswering:\n","            model['qa'] = True\n","        else:\n","            model['qa'] = False\n","\n","        data = {}\n","        data['max_length'] = 96\n","        data['train_split'] = 1\n","        data['pretrained_weights_tokenizer'] = 'bert-base-uncased'\n","        data['tokenizer_class'] = BertTokenizer\n","        \n","        training = {}\n","        training['batch_size'] = 32\n","        training['epochs'] = 5\n","        training['optimizer'] = optim\n","        training['model'] = model\n","        training['data'] = data\n","        training['path'] = path\n","        training['reproducibility'] = False # Flag that enable the use of the older version of bert\n","\n","        pprint.pprint(training)\n","\n","        # Target extraction task and result plots\n","        te_train_loss, te_valid_loss, te_net = te_main_loop(training)\n","        plt.plot(range(training['epochs']), te_valid_loss['loss'])\n","        plt.show()\n","        \n","        # Aggregate all the statistics\n","        stats = [te_train_loss, te_valid_loss]"]},{"cell_type":"markdown","metadata":{"id":"-Icfh7Bn_ine"},"source":["### Target extraction evaluation"]},{"cell_type":"code","execution_count":108,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1641328872880,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"NUkXOcek_sUX"},"outputs":[],"source":["def te_eval(base_path_te_eval):\n","    path = {}\n","    path['train_path'] = os.path.join(__BASEPATH__, __DATA__, 'Dataset_semeval_2014', 'laptop14_train.txt')\n","    path['test_path'] = os.path.join(__BASEPATH__, __DATA__, 'Dataset_semeval_2014','laptop14_test.txt')\n","    \n","    path['base_path_te_eval'] = base_path_te_eval\n","    data = {}\n","    data['pretrained_weights_tokenizer'] = 'bert-base-uncased'\n","    data['tokenizer_class'] = BertTokenizer\n","    data['max_length'] = 96\n","\n","    evaluation = {}\n","    evaluation['data'] = data\n","    evaluation['path'] = path\n","    evaluation['gamma_range'] = [9, 1] # From gamma_range[0] for number of steps equals to gamma_range[1]\n","\n","    pprint.pprint(evaluation)\n","\n","    f1s = target_extraction_eval(evaluation)\n","\n","    print(\"Here it is all the f1:\", f1s)"]},{"cell_type":"markdown","metadata":{"id":"avoewu00_nz4"},"source":["### Polarity classification training"]},{"cell_type":"code","execution_count":109,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1641328872881,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"cRLXT30HA9mq"},"outputs":[],"source":["def pc_train(restart):\n","    path = {}\n","    path['train_path'] = os.path.join(__BASEPATH__, __DATA__, 'Dataset_semeval_2014', 'laptop14_train.txt')\n","    path['test_path'] = os.path.join(__BASEPATH__, __DATA__, 'Dataset_semeval_2014','laptop14_test.txt')\n","\n","    dir = os.path.join(__BASEPATH__, __DATA__, 'Previous_trainings', datetime.now().strftime('%Y_%m_%d_%H:%M:%S'))\n","    os.mkdir(dir)\n","\n","    for res in range(restart):\n","        path['pc_net_save_path'] = os.path.join(dir,'polarity_classification'+str(res)+'.pth')\n","\n","        optim = {}\n","        optim['name'] = 'Adam'\n","        optim['lr'] = 3e-5\n","        optim['momentum'] = 0.9\n","        optim['scheduler'] = 'linear'\n","        optim['warmup'] = 0.1\n","\n","        model = {}\n","        model['model_class'] = DistilBertModel\n","        model['pretrained_weights_model'] = 'distilbert-base-uncased'\n","        model['layers'] = {} \n","        model['all_params_grad'] = True\n","        model['qa'] = False\n","\n","        data = {}\n","        data['max_length'] = 96\n","        data['train_split'] = 1\n","        data['pretrained_weights_tokenizer'] = 'distilbert-base-uncased'\n","        data['tokenizer_class'] = DistilBertTokenizer\n","        \n","        training = {}\n","        training['batch_size'] = 1 # Polarity Classification doesn't work with more than one\n","        training['epochs'] = 10\n","        training['optimizer'] = optim\n","        training['model'] = model\n","        training['data'] = data\n","        training['path'] = path\n","\n","        pprint.pprint(training)\n","\n","        pc_train_loss, pc_valid_loss, pc_net = pc_main_loop(training)\n","        plt.plot(range(training['epochs']), pc_valid_loss['loss'])\n","        plt.show()\n","        \n","        # Aggregate all the statistics\n","        stats = [pc_train_loss, pc_valid_loss]"]},{"cell_type":"markdown","metadata":{"id":"a2FZZNQB_ne8"},"source":["### Polarity classification evaluation"]},{"cell_type":"code","execution_count":110,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1641328872881,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"ANldIIXfBSB0"},"outputs":[],"source":["def pc_eval(base_path_pc_eval):\n","    path = {}\n","    path['train_path'] = os.path.join(__BASEPATH__, __DATA__, 'Dataset_semeval_2014', 'laptop14_train.txt')\n","    path['test_path'] = os.path.join(__BASEPATH__, __DATA__, 'Dataset_semeval_2014','laptop14_test.txt')\n","\n","    path['base_path_pc_eval'] = base_path_pc_eval\n","    data = {}\n","    data['pretrained_weights_tokenizer'] = 'distilbert-base-uncased'\n","    data['tokenizer_class'] = DistilBertTokenizer\n","    data['max_length'] = 96\n","\n","    evaluation = {}\n","    evaluation['data'] = data\n","    evaluation['path'] = path\n","\n","    pprint.pprint(evaluation)\n","\n","    polarity_classification_eval(evaluation)"]},{"cell_type":"markdown","metadata":{"id":"k7b6doLF_nNI"},"source":["### Target extraction and Polarity classification pipeline"]},{"cell_type":"code","execution_count":111,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1641328872882,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"ekUNez9M_b3E"},"outputs":[],"source":["def te_pc_pipe(base_path_eval, restart):\n","    path = {}\n","    path['train_path'] = os.path.join(__BASEPATH__, __DATA__, 'Dataset_semeval_2014', 'laptop14_train.txt')\n","    path['test_path'] = os.path.join(__BASEPATH__, __DATA__, 'Dataset_semeval_2014','laptop14_test.txt')\n","    \n","    path['base_path_eval'] = base_path_eval\n","    data = {}\n","    data['pretrained_weights_tokenizer'] = 'bert-base-uncased'\n","    data['tokenizer_class'] = BertTokenizer\n","    data['max_length'] = 96\n","\n","    evaluation = {}\n","    evaluation['data'] = data\n","    evaluation['path'] = path\n","    evaluation['gamma'] = 8.5\n","\n","    pprint.pprint(evaluation)\n","\n","    test_set = SemEval2014(evaluation['data']['tokenizer_class'], evaluation['data']['pretrained_weights_tokenizer'], \n","                           evaluation['path']['test_path'], evaluation['data']['max_length'])\n","    test_dataloader = DataLoader(test_set, batch_size=1, collate_fn=my_collate, shuffle=False)\n","\n","    pbar = tqdm.tqdm(position=0, leave=True)\n","\n","    te_net = torch.load(os.path.join(evaluation['path']['base_path_eval'],'te_net.pth'), map_location='cpu').to(get_device())\n","    pc_net = torch.load(os.path.join(evaluation['path']['base_path_eval'],'pc_net.pth'), map_location='cpu').to(get_device())\n","\n","    te_net.eval()\n","    pc_net.eval()\n","\n","    print(\"---------------------\")\n","    print(\"\\n Eval started\")\n","\n","    te_net.gamma = evaluation['gamma']\n","    conf_matrix = torch.zeros(2, 2)\n","\n","    with torch.no_grad():\n","        print('\\n ---------------------')\n","        print('\\n Gamma: {} \\n'.format(evaluation['gamma']))\n","\n","        pbar.reset(total=int(len(test_dataloader)))\n","        \n","        for i, element in enumerate(test_dataloader):\n","\n","            o = te_net.inference(element[1], False)\n","            pr = [tuple([int(el[0])-1,int(el[1])-1]) for el in o]\n","            gt_raw = element[3][0]\n","            gt_raw_proc = {}\n","            gt = []\n","            for count, c in enumerate(gt_raw):\n","                gt.append((c[0],c[1]))\n","                gt_raw_proc[(c[0],c[1])] = count\n","            \n","            for p in pr:\n","                if p in gt: \n","                    # True Positive\n","                    pol = gt_raw[gt_raw_proc[p]]\n","                    pred = pc_net.forward(element[1], pol)\n","                    pred = torch.argmax(pred)\n","                    corr = torch.argmax(pol[2])\n","                    if pred==corr:\n","                        conf_matrix[0,0] += 1\n","                    \n","                else:\n","                    # False Positive\n","                    conf_matrix[1,0] += 1\n","            \n","            for g in gt:\n","                if g not in pr:\n","                    conf_matrix[0,1] += 1\n","            \n","            pbar.update()\n","            \n","        \n","        p = conf_matrix[0,0]/(conf_matrix[0,0] + conf_matrix[1,0])\n","        r = conf_matrix[0,0]/(conf_matrix[0,1] + conf_matrix[0,0])\n","        f1 = (2 * p * r) / (p + r)\n","\n","        retrieved = conf_matrix[0,0] + conf_matrix[1,0]\n","        common = conf_matrix[0,0]\n","\n","    print(\"\\n \\n Precision: {}, Recall: {}, F1: {}, Retrieved: {}, Common: {}\".format(p, r, f1, retrieved, common))\n","\n","    pbar.close()\n","    return f1"]},{"cell_type":"markdown","metadata":{"id":"GokfxzAkgrRa"},"source":["## MAIN"]},{"cell_type":"markdown","metadata":{"id":"AE6wgspJBk7j"},"source":["### Main function"]},{"cell_type":"code","execution_count":112,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1641328874557,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"KJBqSc111Jzf"},"outputs":[],"source":["def main(mode=None):\n","    base_path_te_eval = os.path.join(__BASEPATH__, __DATA__, 'Previous_trainings', 'best_te')\n","    base_path_pc_eval = os.path.join(__BASEPATH__, __DATA__, 'Previous_trainings', 'best_pc')\n","    base_path_eval = os.path.join(__BASEPATH__, __DATA__, 'Jointed')\n","    restart = 1 # Number of different random restart for a training session\n","\n","    if mode == 'te_train':\n","        te_train(restart)\n","    elif mode == 'te_eval':\n","        te_eval(base_path_te_eval) \n","    elif mode == 'pc_train':\n","        pc_train(restart) \n","    elif mode == 'pc_eval':\n","        pc_eval(base_path_pc_eval) \n","    elif mode == 'te_pc_pipe':\n","        te_pc_pipe(base_path_eval, restart)\n","    else:\n","        print(f\"Choose a mode between the following: ['te_train', 'te_eval', 'pc_train', 'pc_eval', 'te_pc_pipe']\")"]},{"cell_type":"code","execution_count":113,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39535,"status":"ok","timestamp":1641328914931,"user":{"displayName":"Simone Caldarella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06749461626406930087"},"user_tz":-60},"id":"wJBMXkzieDDm","outputId":"0466ab39-cb0e-423c-dee6-17d88635f2a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'data': {'max_length': 96,\n","          'pretrained_weights_tokenizer': 'bert-base-uncased',\n","          'tokenizer_class': <class 'transformers.models.bert.tokenization_bert.BertTokenizer'>},\n"," 'gamma': 8.5,\n"," 'path': {'base_path_eval': '/content/drive/MyDrive/NLU_Project/Data/Jointed',\n","          'test_path': '/content/drive/MyDrive/NLU_Project/Data/Dataset_semeval_2014/laptop14_test.txt',\n","          'train_path': '/content/drive/MyDrive/NLU_Project/Data/Dataset_semeval_2014/laptop14_train.txt'}}\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/411 [00:00<00:52,  7.81it/s]"]},{"output_type":"stream","name":"stdout","text":["---------------------\n","\n"," Eval started\n","\n"," ---------------------\n","\n"," Gamma: 8.5 \n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 411/411 [00:31<00:00, 12.99it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"," \n"," Precision: 0.494577020406723, Recall: 0.4115523397922516, F1: 0.4492610991001129, Retrieved: 461.0, Common: 228.0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["if __name__ == '__main__':\n","    # All the available modes -> ['te_train', 'te_eval', 'pc_train', 'pc_eval', 'te_pc_pipe']\n","    main(mode='te_pc_pipe')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["jepgL8p_eNmm","yvVH1NVod0_p","36yNWFYVebxL","UP_EVAZUeqKJ","FLqFMQz9fDfm","EeOOtmvDfLN-","7bZSKNlLg6Mt","qLwQF09mfjN-","1l47JCkcflAy","BoXnvkVof2ey","T8VVkWtlf-Je","WUE08zJ8gHH3","xYH-4lB9JdVy","zVcBAkL5HEJH","JCaQ0Mv4Jtqm","u9pXMhHEgcT-","onehYClh_esk","-Icfh7Bn_ine","avoewu00_nz4","a2FZZNQB_ne8"],"name":"NLU_Project.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}